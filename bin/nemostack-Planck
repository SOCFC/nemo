#!/usr/bin/env python

"""We've found that high pass filtering at l > 800 and then subtracting appropriately calibrated 
Planck 217 GHz data does indeed help, though it's not perfect. So, this should allow us to make stacks which
have an unbiased tSZ signal, since we're not filtering down to small angular scales.

We can also adapt this to pull out Y measurements at all object positions (e.g., for checking how these
measurements compare against the Hasselfield et al. (2013) measurements for individual clusters).

"""

import os
import sys
import atpy
from astLib import *
from nemo import actDict
from nemo import catalogTools
from nemo import mapTools
from nemo import photometry
from scipy import ndimage
import numpy
import pyfits
import liteMap
import fftTools
import pylab
import IPython
numpy.random.seed()
#pylab.matplotlib.interactive(True)

#-------------------------------------------------------------------------------------------------------------
def makeLowPassFilteredMap(mapData, wcs, lPass, pad = 20, kern = 10):
    """Returns low pass filtered map, with the filtering done in l space. This zeros all modes at l > lPass.
    
    was pad = 10, kern = 5
    
    """
    
    #paddedData, paddedWCS=makePaddedImageAndWCS(mapData, wcs, 1000)
    #mapData=paddedData
    #wcs=paddedWCS
    
    lm=liteMap.liteMapFromDataAndWCS(mapData, wcs) 
    #lm.data=lm.data*numpy.sqrt(mapDict['weights']/mapDict['weights'].max()) # this appears to make no difference
    apodlm=lm.createGaussianApodization(pad = pad, kern = kern)
    lm.data=lm.data*apodlm.data
    fMap=fftTools.fftFromLiteMap(lm)
    #fMaskedMap.modThetaMap=180.0/(fMaskedMap.modLMap+1)   
    #power=fftTools.powerFromFFT(fMaskedMap)

    lMask=numpy.array(numpy.less(fMap.modLMap, lPass), dtype = float)
    fMap.kMap=fMap.kMap*lMask
    largeScaleMapData=fMap.mapFromFFT()
    
    # Only keep region not affected by apodisation
    apodMask=numpy.array(numpy.greater(apodlm.data, 0.9999), dtype = float)
    
    return largeScaleMapData*apodMask, apodMask

#-------------------------------------------------------------------------------------------------------------
def makePaddedImageAndWCS(inImage, wcs, padAmount):
    """Makes a zero padded image and adjust wcs accordingly.
    
    NOTE: requires images with even size shapes
    
    """
    
    if inImage.shape[0] % 2 != 0 or inImage.shape[1] % 2 != 0:
        raise Exception, "input image does not have even size shape"
    
    paddedModel=numpy.zeros([inImage.shape[0]+padAmount, inImage.shape[1]+padAmount])
    cx, cy=paddedModel.shape[1]/2, paddedModel.shape[0]/2
    xHalfSize, yHalfSize=inImage.shape[1]/2, inImage.shape[0]/2
    paddedModel[cy-yHalfSize:cy+yHalfSize, cx-xHalfSize:cx+xHalfSize]=inImage
 
    paddedWCS=wcs.copy()
    paddedWCS.header.update("CRPIX1", paddedWCS.header['CRPIX1']+padAmount/2)
    paddedWCS.header.update("CRPIX2", paddedWCS.header['CRPIX2']+padAmount/2)
    paddedWCS.updateFromHeader()
    
    return paddedModel, paddedWCS

#-------------------------------------------------------------------------------------------------------------
def getPowerInLRange(mapData, wcs, lMin, lMax):
    """Use flipper to measure mean power inside a range of l.
    
    """
    
    pad = 10
    kern = 5
    lm=liteMap.liteMapFromDataAndWCS(mapData, wcs) 
    #lm.data=lm.data*numpy.sqrt(mapDict['weights']/mapDict['weights'].max()) # this appears to make no difference
    apodlm=lm.createGaussianApodization(pad = pad, kern = kern)
    lm.data=lm.data*apodlm.data
    fMap=fftTools.fftFromLiteMap(lm)
    power=fftTools.powerFromFFT(fMap)
    meanPower, stdDevPower, numPix=power.meanPowerInAnnulus(lMin, lMax)

    return meanPower, fMap, power

#-------------------------------------------------------------------------------------------------------------
def matchPlanckToACTInLSpace(actData, planckData, wcs, lMin, lMax):
    """Attempt to normalise Planck to match ACT over the given l range in l space.
    
    """
    
    # Old: match ACT to Planck --
    #actMeanPower, actFMap, actPower=getPowerInLRange(actData, wcs, lMin, lMax)
    #planckMeanPower, planckFMap, planckPower=getPowerInLRange(planckData, wcs, lMin, lMax)
    #calibRatio=actMeanPower/planckMeanPower

    ## This is how power(mags^2) calculated in nemo (but adjusted so magnitudes obvious)
    ##area=actFMap.Nx*actFMap.Ny*actFMap.pixScaleX*actFMap.pixScaleY
    ##power=(actFMap.kMap.real**2+actFMap.kMap.imag**2) * area / (float(actFMap.Nx*actFMap.Ny))**2
    
    ## Reconstruct calibrated ACT map from mags, phases
    #actMags=numpy.sqrt(actFMap.kMap.real**2+actFMap.kMap.imag**2)
    #actPhases=numpy.arctan2(actFMap.kMap.imag, actFMap.kMap.real)
    #actMagsCalib=actMags/numpy.sqrt(calibRatio)
    #actFMap.kMap.real=actMagsCalib*numpy.cos(actPhases)
    #actFMap.kMap.imag=actMagsCalib*numpy.sin(actPhases)   
    #actDataCalib=actFMap.mapFromFFT()
    
    ## Test - do we match planckMeanPower?
    ##checkMeanPower, checkFMap, checkPower=getPowerInLRange(actDataCalib, wcs, lMin, lMax)
    ##IPython.embed()
    ##sys.exit()
    
    # New: match Planck to ACT --  
    actMeanPower, actFMap, actPower=getPowerInLRange(actData, wcs, lMin, lMax)
    planckMeanPower, planckFMap, planckPower=getPowerInLRange(planckData, wcs, lMin, lMax)
    calibRatio=planckMeanPower/actMeanPower

    # This is how power(mags^2) calculated in nemo (but adjusted so magnitudes obvious)
    #area=actFMap.Nx*actFMap.Ny*actFMap.pixScaleX*actFMap.pixScaleY
    #power=(actFMap.kMap.real**2+actFMap.kMap.imag**2) * area / (float(actFMap.Nx*actFMap.Ny))**2
    
    # Reconstruct calibrated ACT map from mags, phases
    planckMags=numpy.sqrt(planckFMap.kMap.real**2+planckFMap.kMap.imag**2)
    planckPhases=numpy.arctan2(planckFMap.kMap.imag, planckFMap.kMap.real)
    planckMagsCalib=planckMags/numpy.sqrt(calibRatio)
    planckFMap.kMap.real=planckMagsCalib*numpy.cos(planckPhases)
    planckFMap.kMap.imag=planckMagsCalib*numpy.sin(planckPhases)   
    planckDataCalib=planckFMap.mapFromFFT()
    
    # Test - do we match planckMeanPower?
    #checkMeanPower, checkFMap, checkPower=getPowerInLRange(actDataCalib, wcs, lMin, lMax)
    #IPython.embed()
    #sys.exit()
    
    return planckDataCalib

#-------------------------------------------------------------------------------------------------------------
def extractClipForStack(RADeg, decDeg, mapData, wcs, pointSourceMask, clipSizePix,
                        pointSourceExclusionRadiusArcmin = 10.0):
    """Extract a clip from the map at the given position, if it is not point source contaminated.
    
    Returns a 2d array, or None.
    
    """
    
    if wcs.coordsAreInImage(RADeg, decDeg) == True:
        x, y=wcs.wcs2pix(RADeg, decDeg)
        x=int(round(x))
        y=int(round(y))
        clipData=astImages.clipImageSectionPix(mapData, x, y, clipSizePix)
        pointSouceContaminated=False
        if pointSourceMask != None:
            maskData=astImages.clipImageSectionPix(pointSourceMask, x, y, clipSizePix)
            if maskData.nonzero()[0].shape[0] > 0:
                # Don't just throw out if any point source falls in our clip...
                # only throw out if intersects with centre of clip within specified radius
                rArcminMap=photometry.getPixelsDistanceMap({'x': maskData.shape[1]/2, 'y': maskData.shape[1]/2},
                                                            maskData)*wcs.getPixelSizeDeg()*60.0
                inclusionMask=numpy.array(numpy.less(rArcminMap, pointSourceExclusionRadiusArcmin), 
                                            dtype = int)
                if numpy.logical_and(inclusionMask, maskData).nonzero()[0].shape[0] > 0:
                    pointSouceContaminated=True
        if clipData.shape[0] == clipData.shape[1] and pointSouceContaminated == False:
            return clipData
    
    return None  
    
#-------------------------------------------------------------------------------------------------------------
def stackCatalog(sampleDictList, catalogTab, mapData, wcs, outDir, pointSourceMask, clipSizeArcmin = 20.0, 
                 pointSourceExclusionRadiusArcmin = 10.0, RAKey = 'RADeg', decKey = 'decDeg'):
    """Make stacked images for each sample in catalogTab.
        
    Adds catalog and stacked image into sampleDictList entries.
    
    """
        
    # We might want to use interpolation eventually for sub-pixel centering
    # NOTE: we may need to change pixel scale calculation for different projections
    clipSizePix=clipSizeArcmin/(wcs.getPixelSizeDeg()*60.0)
        
    # For the background stack (for photometry), we need to treat sources where we're stacking like we
    # do point sources (to avoid biasing noise high)
    targetCatalog=[]
    for obj in catalogTab:
        targetCatalog.append({'RADeg': obj[RAKey], 'decDeg': obj[decKey]})
    mapDict=mapTools.maskOutSources(mapData, wcs, targetCatalog, 
                                    radiusArcmin = pointSourceExclusionRadiusArcmin, 
                                    mask = 'shuffle')
    targetMask=psMask+mapDict['mask']
    astImages.saveFITS(outDir+os.path.sep+"targetMask.fits", targetMask, wcs) 
    
    # List of possible x, y coords where we can stick background regions
    bckYPosArr, bckXPosArr=numpy.where(targetMask == 0)

    for s in sampleDictList:
        
        sampleTab=getSampleTab(tab, s)
        print "table length sanity checks", len(sampleTab), len(tab), s
        
        # Track which objects are included in the stack - many objects in catalog are outside this field
        sampleTab.add_column('inStack', numpy.zeros(len(sampleTab)))
    
        # Stack objects, also make a background cube here from random positions
        cube=[]
        bckCube=[]
        for i in range(len(sampleTab)):
            obj=sampleTab[i]
            clipData=extractClipForStack(obj[RAKey], obj[decKey], mapData, wcs, pointSourceMask, clipSizePix,
                                         pointSourceExclusionRadiusArcmin = pointSourceExclusionRadiusArcmin)
            if clipData != None:
                sampleTab['inStack'][i]=1
                cube.append(clipData)
                # Now add a corresponding random background location
                bckClipData=None
                count=0
                while bckClipData == None:
                    if count > 1000:
                        raise Exception, "targetMask is packed - giving up looking for background regions"
                    count=count+1
                    randIndex=numpy.random.randint(len(bckYPosArr))
                    bckRADeg, bckDecDeg=wcs.pix2wcs(bckXPosArr[randIndex], bckYPosArr[randIndex])
                    bckClipData=extractClipForStack(bckRADeg, bckDecDeg, mapData, wcs, targetMask, clipSizePix,
                                                    pointSourceExclusionRadiusArcmin = pointSourceExclusionRadiusArcmin)
                bckCube.append(bckClipData)                
        cube=numpy.array(cube)
        bckCube=numpy.array(bckCube)

        # We only care about objects we actually included
        sampleTab=sampleTab.where(numpy.equal(sampleTab['inStack'], 1))
        
        # Make median stack, write to files
        stackedMapData=numpy.median(cube, axis = 0)
        astImages.saveFITS(outDir+os.path.sep+"stack_"+s['label']+".fits", stackedMapData, None)
        bckStackedMapData=numpy.median(bckCube, axis = 0)
        astImages.saveFITS(outDir+os.path.sep+"background_stack_"+s['label']+".fits", bckStackedMapData, None)
        astImages.saveFITS(outDir+os.path.sep+"cube_"+s['label']+".fits", cube, None)
        astImages.saveFITS(outDir+os.path.sep+"background_cube_"+s['label']+".fits", bckCube, None)
        
        # Write table as .fits
        sampleTab.table_name=s['label']
        outFileName=outDir+os.path.sep+"catalog_"+s['label']+".fits"
        if os.path.exists(outFileName) == True:
            os.remove(outFileName)
        sampleTab.write(outFileName)
        
        # Add info to sampleDict in place (just in case we want to fiddle with these later, e.g., measure Y)
        s['stackedMapData']=stackedMapData
        s['backgroundMapData']=bckStackedMapData
        s['stackedCatalog']=sampleTab
        s['mapPixelScaleArcmin']=wcs.getPixelSizeDeg()*60.0

#-------------------------------------------------------------------------------------------------------------
def applyCatalogCuts(tab, catalogCuts):
    """Applies cuts to the catalog, returns the cut catalog.
    
    NOTE: it turns out actDict can't cope with >= in the .par file (even if in quotes)
    
    NOTE: will not work with string values, only numbers (at present).
    
    """
    
    for c in catalogCuts:
        if len(c.split('>')) == 2:
            key, value=c.split('>')
            key=key.rstrip()
            key=key.lstrip()
            value=float(value)
            mask=numpy.greater(tab[key], value)
        elif len(c.split('<')) == 2:
            key, value=c.split('<')
            key=key.rstrip()
            key=key.lstrip()
            value=float(value)
            mask=numpy.greater(tab[key], value)
        elif len(c.split('>=')) == 2:
            key, value=c.split('>=')
            key=key.rstrip()
            key=key.lstrip()
            value=float(value)
            mask=numpy.greater_equal(tab[key], value)
        elif len(c.split('<=')) == 2:
            key, value=c.split('<=')
            key=key.rstrip()
            key=key.lstrip()
            value=float(value)
            mask=numpy.less_equal(tab[key], value)
        elif len(c.split('==')) == 2:
            key, value=c.split('==')
            key=key.rstrip()
            key=key.lstrip()
            value=float(value)
            mask=numpy.equal(tab[key], value)
        else:
            raise Exception, "didn't understand operator in catalogCuts"
        tab=tab.where(mask)
    
    return tab        

#-------------------------------------------------------------------------------------------------------------
def getSampleTab(tab, sampleDict):
    """Extracts sample table from tab given the cuts described in sampleDict. Returns table.
    
    NOTE: 'min_' is interpreted as >= value, 'max_' is interpreted as < value.
    
    """
        
    # Identify constraint keys
    constraintKeys=[]
    for key in sampleDict.keys():
        if key[:4] == "max_" or key[:4] == "min_":
            constraintKey=key[4:]
            if constraintKey not in constraintKeys:
                constraintKeys.append(constraintKey)
    
    for key in constraintKeys:
        mask=numpy.logical_and(numpy.greater_equal(tab[key], sampleDict['min_'+key]), 
                               numpy.less(tab[key], sampleDict['max_'+key]))
        tab=tab.where(mask)
    
    return tab

#-------------------------------------------------------------------------------------------------------------
def makeStackedMapsFigure(sampleDictList, outFileName, cutLevelsMethod = 'abs-max'):
    """Make a matplotlib multi-panel plot.
    
    """
    
    fig=pylab.figure(figsize=(3*len(sampleDictList), 3.5))
    pylab.subplots_adjust(left=0.01, bottom=0.01, right=0.99, top=0.92, wspace=0.02, hspace=0.02)
    subplotCount=0
    for s in sampleDictList:
        subplotCount=subplotCount+1
        pylab.subplot(1, len(sampleDictList), subplotCount)
        smoothedMapData=ndimage.gaussian_filter(s['stackedMapData'], 2.0)
        if cutLevelsMethod == 'relative':
            # Take only the +ve, since signal is -ve and no reason for noise to be asymmetric
            sigma=numpy.std(smoothedMapData[numpy.greater(smoothedMapData, 0)])
            cutLevels=[-10*sigma, 10*sigma]
        elif cutLevelsMethod == 'abs-max':
            # Symmetrical about 0
            absMax=abs(smoothedMapData).max()
            cutLevels=[-absMax, absMax]
        else:
            raise Exception, "didn't understand cutLevelsMethod"
        cutImage=astImages.intensityCutImage(smoothedMapData, cutLevels)       
        pylab.imshow(cutImage['image'], cmap = "spectral", norm = cutImage['norm'])
        pylab.title(s['label']+" (N$_{stack}$=%d)" % (len(s['stackedCatalog'])), fontdict = {'size': 12})
        pylab.xticks([], [])
        pylab.yticks([], [])
    pylab.savefig(outFileName)
    pylab.close()

#-------------------------------------------------------------------------------------------------------------
def measureStackApertureYs(sampleDictList, outDir):
    """Measure Y in several circular apertures from the maps. 
    
    Write a .fits table containing this info.
            
    """

    # Measure Y signal, noise in several circular apertures, we will report all
    # Later we use them to construct profiles also (subtracting circles from circles to make annuli)
    apRadiiArcmin=numpy.linspace(1, 15, 15)
    
    # Store info in a table
    fluxTab=atpy.Table()
    fluxTab.add_column('label', ["__________"]*len(sampleDictList))
    for a in apRadiiArcmin:
        fluxTab.add_column('Y_%darcmin' % (int(a)), numpy.zeros(len(sampleDictList)))
        fluxTab.add_column('YErr_%darcmin' % (int(a)), numpy.zeros(len(sampleDictList)))
        fluxTab.add_column('SNR_%darcmin' % (int(a)), numpy.zeros(len(sampleDictList)))

    # Need to add conversion to appropriate units here
    for s, fluxRow in zip(sampleDictList, fluxTab):
        fluxRow['label']=s['label']
        mapData=mapTools.convertToY(s['stackedMapData'], obsFrequencyGHz = 148.0)
        bckData=mapTools.convertToY(s['backgroundMapData'], obsFrequencyGHz = 148.0)
        pixScaleArcmin=s['mapPixelScaleArcmin']
        rArcminMap=photometry.getPixelsDistanceMap({'x': mapData.shape[1]/2, 'y': mapData.shape[1]/2},
                                                    mapData)*pixScaleArcmin
        for a in apRadiiArcmin:
            # Think about this... is background really zero? We already subtracted it using Planck
            # Signal cannot be +ve (in delta T), but if we take < 0 only, do we bias high by noise?
            # Noise cannot be -ve, so we take abs
            apMask=numpy.less(rArcminMap, a)
            apAreaArcmin2=(apMask.nonzero()[0].shape[0])*(pixScaleArcmin**2)
            apAreaSr=(apMask.nonzero()[0].shape[0])*(numpy.radians(pixScaleArcmin/60.0)**2)
            #signalMask=numpy.logical_and(apMask, numpy.less(mapData, 0))
            signal=numpy.sum(mapData[apMask])*apAreaArcmin2 # background is zero
            noise=numpy.sum(abs(bckData[apMask]))*apAreaArcmin2
            SNR=signal/noise
            fluxRow['Y_%darcmin' % (int(a))]=signal
            fluxRow['YErr_%darcmin' % (int(a))]=noise
            fluxRow['SNR_%darcmin' % (int(a))]=abs(signal/noise)
            
    # Write table
    fluxTab.table_name=outDir
    outFileName=outDir+os.path.sep+"YMeasurements_%s.fits" % (outDir)
    if os.path.exists(outFileName) == True:
        os.remove(outFileName)
    fluxTab.write(outFileName)

#-------------------------------------------------------------------------------------------------------------
def measureCatalogApertureYs(catalogTab, mapData, wcs, pointSourceMask, outDir, clipSizeArcmin = 20.0, RAKey = 'RADeg',
                             decKey = 'decDeg', pointSourceExclusionRadiusArcmin = 10.0):
    """Measure aperture Ys at every object position.
    
    Writes a .fits table containing results.
    
    """

    # Convert to y before we start
    yMapData=mapTools.convertToY(mapData, obsFrequencyGHz = 148.0)
    
    # We might want to use interpolation eventually for sub-pixel centering
    # NOTE: we may need to change pixel scale calculation for different projections
    pixScaleArcmin=wcs.getPixelSizeDeg()*60.0
    clipSizePix=clipSizeArcmin/pixScaleArcmin
    
    # For the background, we need to treat objects as we do point sources (to avoid biasing noise high)
    targetCatalog=[]
    for obj in catalogTab:
        targetCatalog.append({'RADeg': obj[RAKey], 'decDeg': obj[decKey]})
    mapDict=mapTools.maskOutSources(yMapData, wcs, targetCatalog, 
                                    radiusArcmin = pointSourceExclusionRadiusArcmin, 
                                    mask = 'shuffle')
    targetMask=pointSourceMask+mapDict['mask']
    #astImages.saveFITS(outDir+os.path.sep+"targetMask.fits", targetMask, wcs) 
    
    # List of possible x, y coords where we can stick background regions
    bckYPosArr, bckXPosArr=numpy.where(targetMask == 0)
    
    # Measure Y signal, noise in several circular apertures, we will report all
    apRadiiArcmin=numpy.linspace(1, 15, 15)
    
    # Store info in a table
    fluxTab=atpy.Table()
    nameKey=None
    if 'name' in catalogTab.columns:
        nameKey='name'
    elif 'ID' in catalogTab.columns:
        nameKey='ID'
    if nameKey != None:
        fluxTab.add_column('name', catalogTab[nameKey])
    else:
        fluxTab.add_column('name', ["__________"]*len(catalogTab)) # We generate a name... if we don't find an ID or name column       
    fluxTab.add_column('RADeg', catalogTab[RAKey])
    fluxTab.add_column('decDeg', catalogTab[decKey])
    fluxTab.add_column('inMap', numpy.zeros(len(catalogTab))) # will zap out of map objects at the end
    for a in apRadiiArcmin:
        fluxTab.add_column('Ysr_%darcmin' % (int(a)), numpy.zeros(len(catalogTab)))
        fluxTab.add_column('YsrErr_%darcmin' % (int(a)), numpy.zeros(len(catalogTab)))
        fluxTab.add_column('SNR_%darcmin' % (int(a)), numpy.zeros(len(catalogTab)))
    
    # DA is convenient to have if we have a z column
    if 'z' in catalogTab.columns:
        fluxTab.add_column('z', catalogTab['z'])
        fluxTab.add_column('DAMpc', numpy.zeros(len(catalogTab)))
        for obj in fluxTab:
            obj['DAMpc']=astCalc.da(obj['z'])
        
    # Extract a selection of background regions, so we can take average as error
    bckCube=[]
    while(len(bckCube)) < 100:
        count=0
        bckClipData=None
        while bckClipData == None:
            if count > 1000:
                raise Exception, "targetMask is packed - giving up looking for background regions"
            count=count+1
            randIndex=numpy.random.randint(len(bckYPosArr))
            bckRADeg, bckDecDeg=wcs.pix2wcs(bckXPosArr[randIndex], bckYPosArr[randIndex])
            bckClipData=extractClipForStack(bckRADeg, bckDecDeg, yMapData, wcs, targetMask, clipSizePix,
                                            pointSourceExclusionRadiusArcmin = pointSourceExclusionRadiusArcmin)
            if bckClipData != None:
                bckCube.append(bckClipData)
    bckCube=numpy.array(bckCube)
            
    # Now measure Ys for each object
    for obj in fluxTab:
        if obj['name'] == "__________":
            print "generate name"
            IPython.embed()
            sys.exit()
        clipData=extractClipForStack(obj[RAKey], obj[decKey], yMapData, wcs, pointSourceMask, clipSizePix,
                                     pointSourceExclusionRadiusArcmin = pointSourceExclusionRadiusArcmin)
        if clipData != None:
            obj['inMap']=1
            rArcminMap=photometry.getPixelsDistanceMap({'x': clipData.shape[1]/2, 'y': clipData.shape[1]/2},
                                                        clipData)*pixScaleArcmin
            for a in apRadiiArcmin:
                # Think about this... is background really zero? We already subtracted it using Planck
                # Signal cannot be +ve (in delta T), but if we take < 0 only, do we bias high by noise?
                # Noise cannot be -ve, so we take abs
                apMask=numpy.less(rArcminMap, a)
                #apAreaArcmin2=(apMask.nonzero()[0].shape[0])*(pixScaleArcmin**2)
                apAreaSr=(apMask.nonzero()[0].shape[0])*(numpy.radians(pixScaleArcmin/60.0)**2)
                #signalMask=numpy.logical_and(apMask, numpy.less(mapData, 0))
                signal=numpy.sum(clipData[apMask])*apAreaSr # background is zero
                # Noise in each plane of the cube (summed in each aperture)
                apMaskCube=numpy.array([apMask]*len(bckCube))
                noiseInEachPlane=numpy.sum(abs(bckCube*apMaskCube), axis = (1,2))*apAreaSr
                noise=numpy.mean(noiseInEachPlane)
                #noise=numpy.sum(abs(bckData[apMask]))*apAreaArcmin2
                SNR=signal/noise
                obj['Ysr_%darcmin' % (int(a))]=signal
                obj['YsrErr_%darcmin' % (int(a))]=noise
                obj['SNR_%darcmin' % (int(a))]=abs(signal/noise)
    
    # Throw out objects outside map
    fluxTab=fluxTab.where(numpy.equal(fluxTab['inMap'], 1))
    
    # If we have DAMpc, calculate intrinsic SZ
    if 'DAMpc' in fluxTab.columns:
        for a in apRadiiArcmin:
            fluxTab.add_column('DA2_Ysr_%darcmin' % (int(a)), (fluxTab['DAMpc']**2)*fluxTab['Ysr_%darcmin' % (int(a))])
    
    # Write table
    fluxTab.table_name=outDir
    outFileName=outDir+os.path.sep+"catalog_YMeasurements_%s.fits" % (outDir)
    if os.path.exists(outFileName) == True:
        os.remove(outFileName)
    fluxTab.write(outFileName)
                    
#-------------------------------------------------------------------------------------------------------------
def constructYProfiles(sampleDictList, outDir):
    """Construct Y-profiles from info in sampleDictList using output from measureApertureYs.
    
    Make plots too.
    
    Write a .fits table containing the profile data.
    
    """
    
    for s in sampleDictList:
        print "Make Y profiles and figures and write table"
        IPython.embed()
        sys.exit()

#-------------------------------------------------------------------------------------------------------------
# Main
if len(sys.argv) < 2:
    print "Run: % nemostack-Planck < .par file>"
else:
    
    parDictFileName=sys.argv[1]
    parDict=actDict.ACTDict()
    parDict.read_from_file(parDictFileName)
    
    outDir=os.path.split(parDictFileName)[-1].replace(".par", "")+"_"+parDict['stackMode']
    if os.path.exists(outDir) == False:
        os.makedirs(outDir)
            
    # These must have same pixelisation
    actImg=pyfits.open(parDict['a148MapFileName'])
    wcs=astWCS.WCS(actImg[0].header, mode = 'pyfits')
    planckImg=pyfits.open(parDict['planckMapCubeFileName'])

    # Simplest thing: subtract after calibrating ACT to Planck
    lMin=800
    lMax=2000
    a148=actImg[0].data
    p217=planckImg['217'].data  # 217 GHz definitely looks like it works slightly better than CMB

    # Optional clipping
    if 'RADecSection' in parDict.keys():
        RAMin, RAMax, decMin, decMax=parDict['RADecSection']
        aClip=astImages.clipUsingRADecCoords(a148, wcs, RAMin, RAMax, decMin, decMax)
        pClip=astImages.clipUsingRADecCoords(p217, wcs, RAMin, RAMax, decMin, decMax)
        a148=aClip['data']
        p217=pClip['data']
        wcs=aClip['wcs']

    # Maybe these other bands can be useful? e.g., subtract dust?
    #p143=planckImg['143'].data
    #p353=planckImg['353'].data
    #if 'RADecSection' in parDict.keys():
        #RAMin, RAMax, decMin, decMax=parDict['RADecSection']
        #pClip=astImages.clipUsingRADecCoords(p353, wcs, RAMin, RAMax, decMin, decMax)
        #p353=pClip['data']
        #pClip=astImages.clipUsingRADecCoords(p143, wcs, RAMin, RAMax, decMin, decMax)
        #p143=pClip['data']
    #pCube=numpy.array([p143, p217, p353])
    #print "pCube?"
    #IPython.embed()
    #sys.exit()

    # Automatically detect and mask Planck holes (these have absurdly high pixel values which wreck FFTs)
    holeMask=numpy.array(numpy.greater(abs(p217), 1e10), dtype = int)
    p217[numpy.equal(holeMask, 1)]=0.0
    
    # Optional point source masking using catalog
    if 'psCatalogDictList' in parDict.keys():
        psMask=numpy.zeros(p217.shape)+holeMask
        for psCatalogDict in parDict['psCatalogDictList']:
            psTab=atpy.Table(psCatalogDict['fileName'], type = psCatalogDict['type'])
            psRAKey=psCatalogDict['RAColumn']
            psDecKey=psCatalogDict['decColumn']
            psCatalog=[]
            for obj in psTab:
                psCatalog.append({'RADeg': obj[psRAKey], 'decDeg': obj[psDecKey]})
            # Mask could be some value instead (e.g., 0), but 'shuffle' looks pretty good
            p217MapDict=mapTools.maskOutSources(p217, wcs, psCatalog, 
                                                radiusArcmin = psCatalogDict['maskRadiusArcmin'], 
                                                mask = 'shuffle')
            p217=p217MapDict['data']
            a148MapDict=mapTools.maskOutSources(a148, wcs, psCatalog, 
                                                radiusArcmin = psCatalogDict['maskRadiusArcmin'], 
                                                mask = 'shuffle')
            a148=a148MapDict['data']
            psMask=psMask+p217MapDict['mask']
        astImages.saveFITS(outDir+os.path.sep+"pointSourceMask.fits", psMask, wcs)
    else:
        psMask=None
    astImages.saveFITS(outDir+os.path.sep+"p217.fits", p217, wcs)
    astImages.saveFITS(outDir+os.path.sep+"a148.fits", a148, wcs)
        
    # Match Planck map to ACT in l-space over range where ACT not affected by atmos and Planck can see
    p217=matchPlanckToACTInLSpace(a148, p217, wcs, lMin, lMax)

    # Just l > 800 high pass filtered
    a148HighPassFiltered, apodMask=makeLowPassFilteredMap(a148, wcs, lMin)
    a148HighPassFiltered=a148-a148HighPassFiltered
    astImages.saveFITS(outDir+os.path.sep+"a148HighPassFiltered.fits", a148HighPassFiltered, wcs)

    p217LowPassFiltered, apodMask=makeLowPassFilteredMap(p217, wcs, lMin)
    astImages.saveFITS(outDir+os.path.sep+"p217LowPassFiltered.fits", p217LowPassFiltered, wcs)
    p217HighPassFiltered=p217-p217LowPassFiltered
    astImages.saveFITS(outDir+os.path.sep+"p217HighPassFiltered.fits", p217HighPassFiltered, wcs)
    
    # Keeps 800 < l < 2000
    if parDict['stackMode'] == '-Planck':
        p217LFiltered, apodMask=makeLowPassFilteredMap(p217, wcs, lMin)
        p217LFiltered=p217-p217LFiltered
        p217LFiltered, apodMask=makeLowPassFilteredMap(p217LFiltered, wcs, lMax)
        astImages.saveFITS(outDir+os.path.sep+"p217LFiltered.fits", p217LFiltered, wcs)
        
        # Subtract out CMB using Planck lMin < l < lMax
        # Start with a high-pass filtered ACT map to get rid of atmosphere which creates very large scale power
        diff=a148HighPassFiltered-p217LFiltered
        astImages.saveFITS(outDir+os.path.sep+"diff.fits", diff, wcs)
        stackMapData=diff
    elif parDict['stackMode'] == 'highPass':
        stackMapData=a148HighPassFiltered
    else:
        raise Exception, "didn't understand stackMode - should be '-Planck' or 'highPass'"

    # Take apodisation into account in point source mask, so we don't end up stacking things in the edge
    psMask=psMask+(1.0-apodMask)
        
    # Load catalog, apply global cuts    
    tab=atpy.Table(parDict['catalogFileName'])
    tab=applyCatalogCuts(tab, parDict['catalogCuts'])
            
    # Sample definitions
    sampleDictList=parDict['sampleDictList']

    # Photometry at all catalog positions (no stacking)
    # We'll sort out how this fits with stacking later...
    #measureCatalogApertureYs(tab, stackMapData, wcs, psMask, outDir, RAKey = parDict['RAColumn'], decKey = parDict['decColumn'], 
                             #pointSourceExclusionRadiusArcmin = parDict['pointSourceExclusionRadiusArcmin'])
    
    # Stack with no filtering
    stacksDir=outDir+os.path.sep+"stackedMaps"
    if os.path.exists(stacksDir) == False:
        os.makedirs(stacksDir)
    stackCatalog(sampleDictList, tab, stackMapData, wcs, stacksDir, psMask, RAKey = parDict['RAColumn'], 
                 decKey = parDict['decColumn'], clipSizeArcmin = parDict['clipSizeArcmin'],
                 pointSourceExclusionRadiusArcmin = parDict['pointSourceExclusionRadiusArcmin'])
    
    # Photometry on stacked images
    #measureStackApertureYs(sampleDictList, outDir)
    
    # Measure profiles
    #constructYProfiles(sampleDictList, outDir)
    
    # Make a figure with thumbnails
    makeStackedMapsFigure(sampleDictList, outDir+os.path.sep+"%s_stackedMaps.png" % (outDir))
    
