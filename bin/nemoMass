#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""

Calculate masses of clusters detected by nemo

Requires 'massOptions' in nemo .par file (keys: 'redshiftCatalog', 'forcedPhotometry', 'Q')

Run this after filtering / detecting objects in a map with nemo itself

Can be used to obtain 'forced photometry', i.e., mass estimates for objects in redshiftCatalog
(for, e.g., optical stacking)

"""

import os
import sys
import numpy as np
import pylab as plt
import astropy.table as atpy
from astLib import *
from scipy import stats
from scipy import interpolate
from nemo import actDict
from nemo import simsTools
from nemo import mapTools
from nemo import MockSurvey
from nemo import photometry
import astropy.io.fits as pyfits
import time
import IPython
plt.matplotlib.interactive(False)

#------------------------------------------------------------------------------------------------------------
# Main
if len(sys.argv) < 2:
    print "Run: % nemoMass < .par file(s)>"
else:
    
    parDictFileNames=sys.argv[1:]
    
    for parDictFileName in parDictFileNames:
    
        print ">>> Running .par file: %s" % (parDictFileName)
        parDict=actDict.ACTDict()
        parDict.read_from_file(parDictFileName)

        # Output dirs
        if 'outputDir' in parDict.keys():
            rootOutDir=parDict['outDir']
        else:
            if parDictFileName.find(".par") == -1:
                raise Exception, "File must have .par extension"
            rootOutDir=sys.argv[1].replace(".par", "")
        filteredMapsDir=rootOutDir+os.path.sep+"filteredMaps"
        filtersDir=rootOutDir+os.path.sep+"filters"
        diagnosticsDir=rootOutDir+os.path.sep+"diagnostics"
        dirList=[rootOutDir, filteredMapsDir, filtersDir]
        for d in dirList:
            if os.path.exists(d) == False:
                os.makedirs(d)

        # Optional override of default GNFW parameters (used by Arnaud model), if used in filters given
        if 'GNFWParams' not in parDict.keys():
            parDict['GNFWParams']='default'
        for filtDict in parDict['mapFilters']:
            filtDict['params']['GNFWParams']=parDict['GNFWParams']
            
        massOptions=parDict['massOptions']
        
        # Load the nemo catalog and match against the z catalog
        optimalCatalogFileName=rootOutDir+os.path.sep+"%s_optimalCatalog.fits" % (os.path.split(rootOutDir)[-1])           
        nemoTab=atpy.Table().read(optimalCatalogFileName)
        zTab=atpy.Table().read(massOptions['redshiftCatalog'])
        if massOptions['forcedPhotometry'] == False:
            tab=atpy.join(nemoTab, zTab, 'name')
            colsToRemove=[]
            for k in tab.keys():
                if k[-2:] == '_2':
                    colsToRemove.append(k)
            tab.remove_columns(colsToRemove)
            # NOTE: we're going to extract the tile name from 'template'... not very elegant - should just write in the nemo catalog
            colsToKeep=['name', 'RADeg', 'decDeg', 'fixed_SNR', 'fixed_y_c', 'fixed_err_y_c', 'redshift', 'redshiftErr', 'template']
            for k in colsToKeep:
                if k+"_1" in tab.keys():
                    tab.rename_column(k+"_1", k)
            colsToRemove=[]
            for k in tab.keys():
                if k not in colsToKeep:
                    colsToRemove.append(k)
            tab.remove_columns(colsToRemove)
        
        elif massOptions['forcedPhotometry'] == True:
                        
            # This is for "easy set-up" below - we just need a list of extNames
            if 'extNameList' in parDict.keys():
                extNames=parDict['extNameList']
            else:
                raise Exception, "need to add code to scan for extNames in forced photometry mode"
            
            # Filter maps - but should already have been done, this is just for easy set up
            photFilterLabel=parDict['photometryOptions']['photFilter']
            photFilterList=[]
            for filterDict in parDict['mapFilters']:
                if filterDict['label'] == photFilterLabel:
                    photFilterList.append(filterDict)
            imageDict=mapTools.filterMaps(parDict['unfilteredMaps'], photFilterList, extNames = extNames, rootOutDir = rootOutDir)
            
            # Re-jig the catalog into the appropriate format before feeding through photometry routine
            catalog=[]
            for extName in extNames:
                # We need this to check if objects in the catalog are actually in the footprint
                areaMaskImg=pyfits.open(diagnosticsDir+os.path.sep+"areaMask#%s.fits" % (extName))
                areaMask=areaMaskImg[0].data
                wcs=astWCS.WCS(areaMaskImg[0].header, mode = 'pyfits')
                for row in zTab:
                    objDict={}
                    for key in zTab.keys():
                        objDict[key]=row[key]
                    objDict['template']=photFilterLabel+"#"+extName
                    objDict['SNR']=1.0  # Just to keep photometry routine happy; not used for masses
                    x, y=wcs.wcs2pix(objDict['RADeg'], objDict['decDeg'])
                    if x > 0 and y > 0 and x < areaMask.shape[1] and y < areaMask.shape[0]:
                        if areaMask[int(round(y)), int(round(x))] == 1:
                            objDict['x']=x
                            objDict['y']=y
                            catalog.append(objDict)
            imageDict[photFilterLabel+"#"+extName]['catalog']=catalog
            photometry.measureFluxes(imageDict, parDict['photometryOptions'], diagnosticsDir, unfilteredMapsDict = parDict['unfilteredMaps'])
            
            # Make into an atpy table
            # NOTE: we're going to extract the tile name from 'template'... not very elegant - should just write in the nemo catalog
            wantedKeys=['name', 'RADeg', 'decDeg', 'fixed_SNR', 'fixed_y_c', 'fixed_err_y_c', 'redshift', 'redshiftErr', 'template']
            tab=atpy.Table()
            for extName in extNames:
                catalog=imageDict[photFilterLabel+"#"+extName]['catalog']
                for key in wantedKeys:
                    arr=[]
                    for objDict in catalog:
                        if key in objDict.keys():
                            arr.append(objDict[key])
                        else:
                            arr.append(0)
                    tab.add_column(atpy.Column(np.array(arr), key))
            tab=tab[np.where(tab['redshift'] != 0)]
            
            # Flag things with -ve y0~, which we can't do anything with (unless we add stacking / averaging mode)
            for row in tab:
                if row['fixed_y_c'] < 0:
                    print "... %s has fixed_y_c < 0 (and is removed) ..." % (row['name'])
            tab=tab[np.where(tab['fixed_y_c'] > 0)]
        
        # Optional fixed SNR cut
        if 'fixedSNRCut' in massOptions.keys():
            tab=tab[np.where(tab['fixed_SNR'] > massOptions['fixedSNRCut'])]
        
        # Q function (filter mismatch) options
        # NOTE: this should be calculated for the fixed, fiducial cosmology used for object detection
        if massOptions['Q'] == 'H13':
            raise Exception, 'H13 option depreciated - need to replace polynomial with spline fit'
            tckQFit=simsTools.getQCoeffsH13()
        elif massOptions['Q'] == 'fit':
            tckQFitDict=simsTools.fitQ(parDict, diagnosticsDir, filteredMapsDir)
        else:
            raise Exception, "didn't understand choice of Q function in massOptions"
                    
        # Set cosmological parameters for e.g. E(z) calc if these are set in .par file
        # We set them after the Q calc, because the Q calc needs to be for the fiducial cosmology
        # (OmegaM0 = 0.3, OmegaL0 = 0.7, H0 = 70 km/s/Mpc) used in object detection/filtering stage
        # Set-up the mass function stuff also
        # This is for correction of mass bias due to steep cluster mass function
        # Hence minMass here needs to be set well below the survey mass limit
        # areaDeg2 we don't care about here
        minMass=1e13
        areaDeg2=700.
        zMin=0.0
        zMax=2.0
        # H0, OmegaM0, OmegaL0 used for E(z), theta500 calcs in Q
        if 'H0' in massOptions.keys():
            astCalc.H0=massOptions['H0']
            H0=70.
        else:
            H0=70.
        if 'OmegaM0' in massOptions.keys():
            astCalc.OMEGA_M0=massOptions['OmegaM0']
            OmegaM0=massOptions['OmegaM0']
        else:
            OmegaM0=0.3
        if 'OmegaL0' in massOptions.keys():
            astCalc.OMEGA_L0=massOptions['OmegaL0']
            OmegaL0=massOptions['OmegaL0']
        else:
            OmegaL0=0.7
        # OmegaB0, sigma8 only used for mass function Eddington bias correction
        if 'OmegaB0' in massOptions.keys():
            OmegaB0=massOptions['OmegaB0']
        else:
            OmegaB0=0.05
        if 'sigma8' in massOptions.keys():
            sigma8=massOptions['sigma8']
        else:
            sigma8=0.8
        if OmegaL0 + OmegaM0 != 1:
            raise Exception, "only flat cosmologies are currently supported"
        # NOTE: should add sanity check that mockSurvey parameters match astCalc ones
        mockSurvey=MockSurvey.MockSurvey(minMass, areaDeg2, zMin, zMax, H0, OmegaM0, OmegaB0, sigma8)
        
        # Calc masses
        tab.add_column(atpy.Column(np.zeros(len(tab)), "M500"))
        tab.add_column(atpy.Column(np.zeros(len(tab)), "M500_errPlus"))
        tab.add_column(atpy.Column(np.zeros(len(tab)), "M500_errMinus"))
        tab.add_column(atpy.Column(np.zeros(len(tab)), "M500Uncorr"))
        tab.add_column(atpy.Column(np.zeros(len(tab)), "M500Uncorr_errPlus"))
        tab.add_column(atpy.Column(np.zeros(len(tab)), "M500Uncorr_errMinus"))
        if 'rescaleFactor' in massOptions.keys():
            tab.add_column(atpy.Column(np.zeros(len(tab)), "M500Cal"))
            tab.add_column(atpy.Column(np.zeros(len(tab)), "M500Cal_errPlus"))
            tab.add_column(atpy.Column(np.zeros(len(tab)), "M500Cal_errMinus"))
        tab.add_column(atpy.Column(np.zeros(len(tab)), "M200m"))
        tab.add_column(atpy.Column(np.zeros(len(tab)), "M200m_errPlus"))
        tab.add_column(atpy.Column(np.zeros(len(tab)), "M200m_errMinus"))
        tab.add_column(atpy.Column(np.zeros(len(tab)), "M200mUncorr"))
        tab.add_column(atpy.Column(np.zeros(len(tab)), "M200mUncorr_errPlus"))
        tab.add_column(atpy.Column(np.zeros(len(tab)), "M200mUncorr_errMinus"))
        #tab.add_column(atpy.Column(np.zeros(len(tab)), "Q"))
        #tab.add_column(atpy.Column(np.zeros(len(tab)), "Q_err"))
        for row in tab:
            print "... %s (%.3f +/- %.3f) ..." % (row['name'], row['redshift'], row['redshiftErr'])
            extName=row['template'].split("#")[-1]
            massDict=simsTools.calcM500Fromy0(row['fixed_y_c']*1e-4, row['fixed_err_y_c']*1e-4, 
                                              row['redshift'], row['redshiftErr'],
                                              tenToA0 = massOptions['tenToA0'],
                                              B0 = massOptions['B0'], 
                                              Mpivot = massOptions['Mpivot'], 
                                              sigma_int = massOptions['sigma_int'],
                                              tckQFit = tckQFitDict[extName], mockSurvey = mockSurvey, 
                                              applyMFDebiasCorrection = True,
                                              H0 = H0, OmegaM0 = OmegaM0, OmegaL0 = OmegaL0)
            row['M500']=massDict['M500']
            row['M500_errPlus']=massDict['M500_errPlus']
            row['M500_errMinus']=massDict['M500_errMinus']
            row['M500Uncorr']=massDict['M500Uncorr']
            row['M500Uncorr_errPlus']=massDict['M500Uncorr_errPlus']
            row['M500Uncorr_errMinus']=massDict['M500Uncorr_errMinus']
            # Mass conversion
            row['M200m']=simsTools.convertM500cToM200m(massDict['M500']*1e14, row['redshift'])/1e14
            row['M200m_errPlus']=(row['M500_errPlus']/row['M500'])*row['M200m']
            row['M200m_errMinus']=(row['M500_errMinus']/row['M500'])*row['M200m']
            row['M200mUncorr']=simsTools.convertM500cToM200m(massDict['M500Uncorr']*1e14, row['redshift'])/1e14
            row['M200mUncorr_errPlus']=(row['M500Uncorr_errPlus']/row['M500Uncorr'])*row['M200mUncorr']
            row['M200mUncorr_errMinus']=(row['M500Uncorr_errMinus']/row['M500Uncorr'])*row['M200mUncorr']
            # Re-scaling (e.g., using richness-based weak-lensing mass calibration)
            row['M500Cal']=massDict['M500']/massOptions['rescaleFactor']
            row['M500Cal_errPlus']=np.sqrt(np.power(row['M500_errPlus']/row['M500'], 2) + \
                                           np.power(massOptions['rescaleFactorErr']/massOptions['rescaleFactor'], 2))*row['M500Cal']
            row['M500Cal_errMinus']=np.sqrt(np.power(row['M500_errMinus']/row['M500'], 2) + \
                                            np.power(massOptions['rescaleFactorErr']/massOptions['rescaleFactor'], 2))*row['M500Cal']
            
        # Tidy up and save
        # We delete some columns here to save duplicating in sourcery database
        #tab.remove_columns(['fixed_SNR', 'fixed_y_c', 'fixed_err_y_c'])
        if massOptions['forcedPhotometry'] == False:
            outFileName=optimalCatalogFileName.replace("_optimalCatalog.fits", "_M500.fits")
        else:
            outFileName=rootOutDir+os.path.sep+os.path.split(massOptions['redshiftCatalog'])[-1].replace(".fits", "_M500.fits")
        if os.path.exists(outFileName) == True:
            os.remove(outFileName)
        tab.write(outFileName)


