#!/usr/bin/env python

"""

nemo driver script: for filtering maps and finding clusters

"""

import sys
#print("Running under python: %s" % (sys.version))
import os
import datetime
from nemo import *
import nemo
from nemo import MockSurvey
import argparse
import astropy
import astropy.table as atpy
import astropy.io.fits as pyfits
from astLib import astWCS
import numpy as np
import pylab
import pickle
import types
import yaml
import IPython
pylab.matplotlib.interactive(False)
plotSettings.update_rcParams()

#------------------------------------------------------------------------------------------------------------
if __name__ == '__main__':

    parser=argparse.ArgumentParser("nemo")
    parser.add_argument("configFileName", help="""A .yml configuration file.""")
    parser.add_argument("-M", "--mpi", dest="MPIEnabled", action="store_true", help="""Enable MPI. If you 
                        want to use this, run with e.g., mpiexec -np 4 nemo configFile.yml -M""", 
                        default = False)
    parser.add_argument("-n", "--no-strict-errors", dest="noStrictMPIExceptions", action="store_true", 
                        help="""Disable strict exception handling (applies under MPI only, i.e., must be
                        used with the -M switch). If you use this option, you will get the full traceback
                        when a Python Exception is triggered, but the code may not terminate. This is due
                        to the Exception handling in mpi4py.""", 
                        default = False)
    args=parser.parse_args()
    
    if args.noStrictMPIExceptions == True:
        strictMPIExceptions=False
    else:
        strictMPIExceptions=True
    
    parDictFileName=args.configFileName
    config=startUp.NemoConfig(parDictFileName, MPIEnabled = args.MPIEnabled, 
                              strictMPIExceptions = strictMPIExceptions)
    
    imageDict=pipelines.filterMapsAndMakeCatalogs(config)

    # Q function (filter mismatch) - if needed options have been given
    # We may as well do this here to save having to run nemoMass separately (though we still can...)
    # (it's the Q calc in nemoMass that takes time - but it's only a couple of min per field in parallel)
    if 'photFilter' in config.parDict.keys() and config.parDict['photFilter'] is not None:
        if os.path.exists(config.selFnDir+os.path.sep+"QFit.fits") == False:
            signals.fitQ(config)
        
    # Optional position recovery test (how well do we recovery positions as fn. of S/N?)
    if 'positionRecoveryTest' in config.parDict.keys() and config.parDict['positionRecoveryTest'] == True:
        posRecTable=maps.positionRecoveryTest(config, imageDict)
    else:
        posRecTable=None
            
    # Estimate of contamination from running cluster finding over inverted map
    if 'estimateContaminationFromInvertedMaps' in list(config.parDict.keys()) and config.parDict['estimateContaminationFromInvertedMaps'] == True:
        conTabDict=maps.estimateContaminationFromInvertedMaps(config, imageDict)
    else:
        conTabDict={}
        
    # Estimate of contamination by generating a fake sky with noise, and running detection algorithm over it
    # Ultimately we want this and the above ^^^ to appear on the same plot for comparison
    if 'estimateContaminationFromSkySim' in list(config.parDict.keys()) and config.parDict['estimateContaminationFromSkySim'] == True:
        skySimConTabDict=maps.estimateContaminationFromSkySim(config, imageDict) 
    else:
        skySimConTabDict={}
    
    # This just combines inverted maps contamination results and skySim (under different keys)
    # So we only feed one dictionary into the plotting routine (see below)
    for k in list(skySimConTabDict.keys()):
        conTabDict[k]=skySimConTabDict[k]

    # Moved calculation of selection function parts here as it's very quick in parallel
    if 'calcSelFn' in list(config.parDict.keys()) and config.parDict['calcSelFn'] == True:
        # Since a fiducial cosmology (OmegaM0 = 0.3, OmegaL0 = 0.7, H0 = 70 km/s/Mpc) was used in the object detection/filtering stage, we use the same one here      
        minMass=8e13
        areaDeg2=400.0  # Don't care what value this has, as we'll sim up an arbitrary number of clusters anyway
        zMin=0.0
        zMax=2.0
        H0=70.
        Om0=0.30
        Ob0=0.05
        sigma_8=0.8
        mockSurvey=MockSurvey.MockSurvey(minMass, areaDeg2, zMin, zMax, H0, Om0, Ob0, sigma_8, enableDrawSample = True)
        selFnCollection=pipelines.makeSelFnCollection(config, mockSurvey)
    else:
        selFnCollection={}
    
    # MPI: gather together and merge all of the catalogs from each process, and contamination test results
    # This needs tidying up...
    if config.MPIEnabled == True:
        optimalCatalogList=config.comm.gather(imageDict['optimalCatalog'], root = 0)
        posRecTableList=config.comm.gather(posRecTable, root = 0)
        conKeysList=list(conTabDict.keys())
        conTabDictList=config.comm.gather(conTabDict, root = 0)
        if 'calcSelFn' in list(config.parDict.keys()) and config.parDict['calcSelFn'] == True:
            gathered_selFnCollections=config.comm.gather(selFnCollection, root = 0)
        if config.rank != 0:
            assert optimalCatalogList is None
            print("... MPI rank %d finished ..." % (config.rank))
            sys.exit()
        else:
            print("... gathering catalogs ...")
            toStack=[]  # We sometimes return [] if no objects found - we can't vstack those
            for collectedTab in optimalCatalogList:
                if type(collectedTab) == astropy.table.table.Table:
                    toStack.append(collectedTab)
            optimalCatalog=atpy.vstack(toStack)
            print("... gathering position recovery tests ...")
            toAverage=[]
            for posRecTable in posRecTableList:
                if type(posRecTable) == astropy.table.table.Table:
                    toAverage.append(posRecTable)
            if len(toAverage) > 0:
                posRecTable=atpy.vstack(toAverage)
                for key in posRecTable.keys():
                    posRecTable[key]=posRecTable[key]/len(toAverage)
            else:
                posRecTable=None
            print("... gathering and averaging contamination estimates ...")
            avConTabDict={}
            for k in conKeysList:
                tabList=[]
                avTab=None
                tabCount=0
                for tabDict in conTabDictList:
                    tab=tabDict[k]
                    if type(avTab) == type(None):
                        avTab=atpy.Table()
                        for colName in list(tab.keys()):
                            avTab.add_column(atpy.Column(np.zeros(len(tab)), colName))
                    for colName in list(avTab.keys()):
                        avTab[colName]=avTab[colName]+tab[colName]
                    tabCount=tabCount+1
                for colName in list(avTab.keys()):
                    avTab[colName]=avTab[colName]/float(tabCount)
                mask=np.greater(avTab['cumSumSimCandidates'], 0)
                avTab['cumContamination']=atpy.Column(np.zeros(len(avTab)), 'cumContamination')
                avTab['cumContamination'][mask]=avTab['cumSumSimCandidates'][mask]/avTab['cumSumRealCandidates'][mask]
                avConTabDict[k]=avTab
            conTabDictList=avConTabDict
            # And write average as .fits table(s)
            # (if we didn't run under MPI, already averaged)
            for k in list(avConTabDict.keys()):
                fitsOutFileName=config.diagnosticsDir+os.path.sep+"%s_contaminationEstimate_%s.fits" % (k, "_average")
                conTab=avConTabDict[k]
                conTab.write(fitsOutFileName, overwrite = True) 
            # Selection function bits
            if 'calcSelFn' in list(config.parDict.keys()) and config.parDict['calcSelFn'] == True:
                print("... gathering selection function results ...")
                all_selFnCollection={'full': []}
                for key in selFnCollection.keys():
                    if key not in all_selFnCollection.keys():
                        all_selFnCollection[key]=[]
                for selFnCollection in gathered_selFnCollections:
                    for key in all_selFnCollection.keys():
                        all_selFnCollection[key]=all_selFnCollection[key]+selFnCollection[key]
                selFnCollection=all_selFnCollection
    else:
        optimalCatalog=imageDict['optimalCatalog']
    
    # Plot tile-averaged position recovery test
    if posRecTable is not None:
        posRecTable.write(config.diagnosticsDir+os.path.sep+"positionRecovery_average.fits", overwrite = True) 
        maps.plotPositionRecovery(posRecTable, config.diagnosticsDir+os.path.sep+"positionRecovery_average",
                                  percentilesToPlot = [50, 90])
        
    # Plot contamination together
    if conTabDict != {}:
        maps.plotContamination(conTabDict, config.diagnosticsDir)           
    
    # Strip out duplicates (this is necessary when run in tileDir mode under MPI)
    if len(optimalCatalog) > 0:
        optimalCatalog, numDuplicatesFound, names=catalogs.removeDuplicates(optimalCatalog)
    # We can do this twice as a sanity check... not necessary if we add a proper test elsewhere
    #optimalCatalog, numDuplicatesFound, names=catalogs.removeDuplicates(optimalCatalog)
    #assert(numDuplicatesFound == 0)

    optimalCatalogFileName=config.rootOutDir+os.path.sep+"%s_optimalCatalog.csv" % (os.path.split(config.rootOutDir)[-1])           
    catalogs.writeCatalog(optimalCatalog, optimalCatalogFileName)
    catalogs.writeCatalog(optimalCatalog, optimalCatalogFileName.replace(".csv", ".fits"))
            
    addInfo=[{'key': 'SNR', 'fmt': '%.1f'}]
    catalogs.catalog2DS9(optimalCatalog, optimalCatalogFileName.replace(".csv", ".reg"),
                         addInfo = addInfo, color = "cyan") 
        
    # Stitch together map tiles - these are 'quicklook' images (downsampled by factor 4 in resolution)
    # The stitchTiles routine will only write output if there are multiple maps matching the file pattern
    if 'makeQuickLookMaps' in config.parDict.keys() and config.parDict['makeQuickLookMaps'] == True:
        # RMS (we don't save quicklook to selFnDir - users should use full-fat maps to be sure) 
        maps.stitchTiles(config.selFnDir+os.path.sep+"RMSMap*.fits", 
                         config.diagnosticsDir+os.path.sep+"quicklook_RMSMap.fits", 
                         config.quicklookWCS, config.quicklookShape, fluxRescale = config.quicklookScale)
        # S/N maps at reference filter scale
        if config.parDict['photFilter'] is not None:
            maps.stitchTiles(config.filteredMapsDir+os.path.sep+"*"+os.path.sep+"%s*SNMap.fits" % (config.parDict['photFilter']), 
                             config.filteredMapsDir+os.path.sep+"quicklook_%s_SNMap.fits" % (config.parDict['photFilter']), 
                             config.quicklookWCS, config.quicklookShape, fluxRescale = config.quicklookScale)    

    # Cache file containing weights for relativistic corrections
    # Saves doing this later (e.g., when nemoMass or nemoSelFn run) and it's quick to do
    signals.getFRelWeights(config)

    if 'calcSelFn' in list(config.parDict.keys()) and config.parDict['calcSelFn'] == True:
        # Survey completeness stats now all lumped together in one routine
        # This also make survey-averaged (M, z) grid(s) as used by e.g. HSC lensing analysis
        completeness.completenessByFootprint(selFnCollection, mockSurvey, config.diagnosticsDir, 
                                            additionalLabel = "_"+config.parDict['selFnOptions']['method'].replace(" ", "_"))
        
        # If we made mass limit maps...
        # ... make cumulative area versus mass limit plot(s)
        # ... and downsampled full area (untiled) map(s) and plot(s) of the mass limit
        if 'massLimitMaps' in config.parDict['selFnOptions'].keys():
            print(">>> Making cumulative area plots and full survey mass limit plots ...")
            for massLimitDict in config.parDict['selFnOptions']['massLimitMaps']:
                completeness.cumulativeAreaMassLimitPlot(massLimitDict['z'], config.diagnosticsDir, config.selFnDir, config.allTileNames) 
                completeness.makeFullSurveyMassLimitMapPlot(massLimitDict['z'], config)
        
    # Tidy up by making MEF files and deleting the (potentially 100s) of per-tile files made
    # This also puts Q fits into one file - so we need to run this regardless
    completeness.tidyUp(config)
        
    
