#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""

Calculate mass completeness limits, assuming the RMS map(s) are correct

"""

import os
import sys
import resource
import glob
import numpy as np
import pylab as plt
import astropy.table as atpy
from astLib import *
from scipy import stats
from scipy import interpolate
from scipy import ndimage
from scipy import optimize
from nemo import actDict
from nemo import simsTools
from nemo import mapTools
from nemo import MockSurvey
from nemo import SelFn
from nemo import photometry
from nemo import plotSettings
import pickle
import nemoCython
import astropy.io.fits as pyfits
import time
import matplotlib.cm as cm
import matplotlib
import IPython
plt.matplotlib.interactive(False)

#------------------------------------------------------------------------------------------------------------
def getTileTotalAreaDeg2(extName, diagnosticsDir):
    """Returns total area of the tile pointed at by extName (taking into account survey mask and point
    source masking).
    
    """
    
    areaImg=pyfits.open(diagnosticsDir+os.path.sep+"areaMask#%s.fits" % (extName))
    areaMap=areaImg[0].data
    wcs=astWCS.WCS(areaImg[0].header, mode = 'pyfits')
    areaMapSqDeg=(mapTools.getPixelAreaArcmin2Map(areaMap, wcs)*areaMap)/(60**2)
    totalAreaDeg2=areaMapSqDeg.sum()
    
    return totalAreaDeg2

#------------------------------------------------------------------------------------------------------------
def getRMSTab(extName, photFilterLabel, diagnosticsDir):
    """Makes a table containing fraction of map area in tile pointed to by extName against RMS values
    (so this compresses the information in the RMS maps). The first time this is run takes ~200 sec (for a
    1000 sq deg tile), but the result is cached.
        
    Returns RMSTab
    
    """
    
    # This can probably be sped up, but takes ~200 sec for a ~1000 sq deg tile, so we cache
    RMSTabFileName=diagnosticsDir+os.path.sep+"RMSTab_%s.fits" % (extName)
    if os.path.exists(RMSTabFileName) == False:
        print("... making %s ..." % (RMSTabFileName))
        RMSImg=pyfits.open(diagnosticsDir+os.path.sep+"RMSMap_Arnaud_M2e14_z0p4#%s.fits" % (extName))
        RMSMap=RMSImg[0].data
        RMSValues=np.unique(RMSMap[np.nonzero(RMSMap)])

        areaImg=pyfits.open(diagnosticsDir+os.path.sep+"areaMask#%s.fits" % (extName))
        areaMap=areaImg[0].data
        wcs=astWCS.WCS(areaImg[0].header, mode = 'pyfits')
        areaMapSqDeg=(mapTools.getPixelAreaArcmin2Map(areaMap, wcs)*areaMap)/(60**2)
        totalAreaDeg2=areaMapSqDeg.sum()
        
        fracArea=np.zeros(len(RMSValues))
        for i in range(len(RMSValues)):
            fracArea[i]=areaMapSqDeg[np.equal(RMSMap, RMSValues[i])].sum()
        RMSTab=atpy.Table()
        RMSTab.add_column(atpy.Column(fracArea, 'fracArea'))
        RMSTab.add_column(atpy.Column(RMSValues, 'y0RMS'))
        RMSTab.write(RMSTabFileName)
    else:
        print("... reading %s ..." % (RMSTabFileName))
        RMSTab=atpy.Table().read(RMSTabFileName)
    
    return RMSTab

#------------------------------------------------------------------------------------------------------------
def calcTileWeightedAverageNoise(extName, photFilterLabel, diagnosticsDir):
    """Returns weighted average noise value in the tile.
    
    """

    RMSTab=getRMSTab(extName, photFilterLabel, diagnosticsDir)
    RMSValues=np.array(RMSTab['y0RMS'])
    fracArea=np.array(RMSTab['fracArea'])
    tileRMSValue=np.average(RMSValues, weights = fracArea)

    return tileRMSValue

#------------------------------------------------------------------------------------------------------------
def rayleighFlipped(log10M, loc, scale):
    """This is a good functional form to fit to completeness as a function of mass. It's asymmetric, so
    it can fit both the low and high completeness ends with one function (previously we used Gaussian cdf,
    but that isn't a good fit when intrinsic scatter is turned on).
    
    """
    return (1-stats.rayleigh.cdf(log10M, loc = loc, scale = scale))[::-1]

#------------------------------------------------------------------------------------------------------------
def calcCompleteness(y0Noise, SNRCut, extName, mockSurvey, scalingRelationDict, tckQFitDict, diagnosticsDir,
                     zRange = [0.05, 0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0],
                     fitTabFileName = None):
    """Calculate completeness as a function of M500, z, for assumed fiducial cosmology and scaling relation,
    at the given SNRCut and noise level. Intrinsic scatter in the scaling relation is taken into account.
    
    If fitTabFileName != None, saves the resulting model (and sim results) as .fits table(s) under 
    diagnosticsDir. Also saves a diagnostic plot of completeness for that tile.
    
    Returns fitTab
    
    """
    
    if fitTabFileName != None and os.path.exists(fitTabFileName) == True:
        fitTab=atpy.Table().read(fitTabFileName)
        return fitTab
    
    # What we'll generally want is the completeness at some fixed z, for some assumed scaling relation
    tenToA0, B0, Mpivot, sigma_int=[scalingRelationDict['tenToA0'], scalingRelationDict['B0'], 
                                    scalingRelationDict['Mpivot'], scalingRelationDict['sigma_int']]

    # This is the minimum number to draw - gets multiplied up as needed to get good statistics...
    # ... and this is the minimum number of detected sim cluster we need to get a good completeness curve and model fit
    # This combination peaks at ~5 Gb of RAM used 
    numMockClusters=10000
    minAllowedDetections=4000
    maxMultiplier=8000
    minDrawNoiseMultiplier=SNRCut-3.  # This is only for an estimate, but can make a huge difference in speed if set higher (not always robust though)

    # Binning used for fitting
    binEdges=np.arange(13.5, 16.0, 0.05)
    binCentres=(binEdges[:-1]+binEdges[1:])/2.

    # For storing results - this one is not strictly necessary, but could be used for sanity checking fit results
    # Table format: column of log10M values, then columns (labelled with redshift) of completeness versus mass
    completenessTab=atpy.Table()
    completenessTab.add_column(atpy.Column(binCentres, 'log10M'))

    t00=time.time()

    # Stores Rayleigh cumulative distribution function (flipped etc.) fits at each z
    fitTab=atpy.Table()
    fitTab.add_column(atpy.Column(zRange, 'z'))
    fitTab.add_column(atpy.Column(np.zeros(len(zRange)), 'loc'))
    fitTab.add_column(atpy.Column(np.zeros(len(zRange)), 'scale'))

    # Need these when applying the fit - only valid in this range for given loc, scale
    fitTab.add_column(atpy.Column(np.zeros(len(zRange)), 'log10MMin'))  
    fitTab.add_column(atpy.Column(np.zeros(len(zRange)), 'log10MMax'))

    # We may as well store 90% completeness limit in here as well
    fraction=0.9
    fitTab.add_column(atpy.Column(np.zeros(len(zRange)), 'log10MLimit_90%'))

    for iz in range(len(zRange)):

        t0=time.time()    
        z=zRange[iz]
        #print("... z = %.2f ..." % (z))
        zIndex=np.where(abs(mockSurvey.z-z) == abs(mockSurvey.z-z).min())[0][0]
        
        # Used in Q-calc below...
        Ez=astCalc.Ez(z)
        Hz=astCalc.Ez(z)*astCalc.H0  
        G=4.301e-9  # in MSun-1 km2 s-2 Mpc
        criticalDensity=(3*np.power(Hz, 2))/(8*np.pi*G)
        
        # Ajusting mass limit for draws according to RMS - trick to avoid drawing loads of clusters we'll never see
        # This is ok as just a rough estimate
        minLog10MDraw=np.log10(Mpivot*np.power((y0Noise*minDrawNoiseMultiplier)/(tenToA0*np.power(astCalc.Ez(z), 2)), 1/(1+B0)))
        testDraws=np.linspace(0, 1, 1000)
        testLog10M=interpolate.splev(testDraws, mockSurvey.tck_log10MRoller[zIndex])
        minDraw=testDraws[np.argmin(abs(testLog10M-minLog10MDraw))]
        
        # Draw masses from the mass function...    
        numDetected=0
        mockClusterMultiplier=1
        exceededMultiplierCount=0
        while numDetected < minAllowedDetections:
            log10Ms=interpolate.splev(np.random.uniform(minDraw, 1, int(mockClusterMultiplier*numMockClusters)), mockSurvey.tck_log10MRoller[zIndex])
                        
            # Sort masses here, as we need in order biggest -> smallest for fast completeness calc
            log10Ms.sort()
            log10Ms=log10Ms[::-1]
            
            # For speedy mock "observations" - since we have fixed z
            fitM500s=np.power(10, np.linspace(log10Ms.min(), log10Ms.max(), 100))
            fitTheta500s=np.zeros(len(fitM500s))
            for i in range(len(fitM500s)):
                M500=fitM500s[i]
                R500Mpc=np.power((3*M500)/(4*np.pi*500*criticalDensity), 1.0/3.0)                     
                theta500Arcmin=np.degrees(np.arctan(R500Mpc/astCalc.da(z)))*60.0
                fitTheta500s[i]=theta500Arcmin
            tckLog10MToTheta500=interpolate.splrep(np.log10(fitM500s), fitTheta500s)
            theta500s=interpolate.splev(log10Ms, tckLog10MToTheta500)
            Qs=interpolate.splev(theta500s, tckQFitDict[extName])
            fRels=simsTools.calcFRel(z, np.power(10, log10Ms))
            true_y0s=tenToA0*np.power(astCalc.Ez(z), 2)*np.power(np.power(10, log10Ms)/Mpivot, 1+B0)*Qs*fRels
            
            # Mock "observations" (apply intrinsic scatter and noise)...
            scattered_y0s=np.exp(np.random.normal(np.log(true_y0s), sigma_int, len(true_y0s)))        
            measured_y0s=np.random.normal(scattered_y0s, y0Noise)
            # Comment out above and uncomment below to switch off intrinsic scatter
            #measured_y0s=np.random.normal(true_y0s, y0Noise)
            
            # Check selection - did we manage to select enough objects?
            y0Lim_selection=SNRCut*y0Noise  # y0Noise = RMS
            t111=time.time()
            numDetected=np.greater(measured_y0s, y0Lim_selection).sum()
            if numDetected == 0:
                mockClusterMultiplier=maxMultiplier
            elif numDetected < minAllowedDetections:
                mockClusterMultiplier=1.2*(minAllowedDetections/(float(numDetected)/mockClusterMultiplier))
                #print("... mockClusterMultiplier = %.1f ..." % (mockClusterMultiplier))
                if mockClusterMultiplier > maxMultiplier:
                    mockClusterMultiplier=maxMultiplier
                    exceededMultiplierCount=exceededMultiplierCount+1
                if exceededMultiplierCount > 2:
                    raise Exception, "exceeded maxMultiplier too many times"
        
        # Calculate completeness
        detArr=np.cumsum(np.greater(measured_y0s, y0Lim_selection))
        allArr=np.arange(1, len(log10Ms)+1, 1, dtype = float)
        completeness=detArr/allArr
        
        # Average/downsample: both for storage, and to deal with low numbers at high mass end (and spline fits later)
        binnedCompleteness=np.zeros(len(binEdges)-1)
        binnedCounts=np.zeros(len(binEdges)-1, dtype = float)
        for i in range(len(binEdges)-1):
            mask=np.logical_and(np.greater(log10Ms, binEdges[i]), np.less(log10Ms, binEdges[i+1]))
            if mask.sum() > 0:
                binnedCompleteness[i]=np.median(completeness[mask])
            binnedCounts[i]=mask.sum()
            # Never allow completness to decrease at higher mass (this would be a lower limit)
            if binnedCompleteness[i] < binnedCompleteness[i-1]:
                binnedCompleteness[i]=binnedCompleteness[i-1]
        completenessTab.add_column(atpy.Column(binnedCompleteness, z))
        
        # NOTE: Neither cdf nor error function can fit, because of intrinsic scatter (assymetric at low/high completeness)
        # However, cdf for Rayleigh distribution can be fiddled to look like we what we have...
        # We need the min, max of the range the fit is done over for finer binning to work (see below)
        fraction=0.5
        locGuess=log10Ms[np.argmin(abs(fraction-completeness))]
        fitResult=optimize.curve_fit(rayleighFlipped, binCentres, binnedCompleteness, p0 =[locGuess, 0.2])
        fittedLoc=fitResult[0][0]
        fittedScale=fitResult[0][1]
        fitTab['loc'][iz]=fittedLoc
        fitTab['scale'][iz]=fittedScale   
        fitTab['log10MMin'][iz]=binCentres.min()
        fitTab['log10MMax'][iz]=binCentres.max()

        # While we're here, we may as well store 90% completeness limit
        fraction=0.9    
        fineLog10Bins=np.linspace(fitTab['log10MMin'][iz], fitTab['log10MMax'][iz], 1000)
        fineCompleteness=rayleighFlipped(fineLog10Bins, fitTab['loc'][iz], fitTab['scale'][iz])
        log10MassLimit=fineLog10Bins[np.argmin(abs(fraction-fineCompleteness))]
        fitTab['log10MLimit_90%'][iz]=log10MassLimit
        #print("... 90%% completeness mass limit at z = %.1f: %.3e MSun ..." % (z, np.power(10, log10MassLimit)))
        t1=time.time()
        #print("... time taken = %.3f sec ..." % (t1-t0))

    t11=time.time()
    #print("... total time take for %s = %.3f sec ..." % (extName, t11-t00))
    
    if fitTabFileName != None:

        # Save both the fit results and the binned data they are based on
        outFileNames=[fitTabFileName, diagnosticsDir+os.path.sep+"selFn_completenessTab#%s.fits" % (extName)]
        tabs=[fitTab, completenessTab]
        for outFileName, tab in zip(outFileNames, tabs):
            if os.path.exists(outFileName) == True:
                os.remove(outFileName)
            tab.write(outFileName)
        
        # Tile-averaged 90% completeness mass limit and plot (will be a good, quick sanity check)
        massLimit_90Complete=np.power(10, np.array(fitTab['log10MLimit_90%']))/1e14
        zRange=np.array(fitTab['z'])
        averageMassLimit_90Complete=massLimit_90Complete[np.logical_and(np.greater(zRange, 0.2), np.less(zRange, 1.0))].mean()
        makeMassLimitVRedshiftPlot(massLimit_90Complete, zRange, diagnosticsDir+os.path.sep+"completeness90Percent#%s.pdf" % (extName), 
                                   title = "%s: $M_{\\rm 500c}$ / $10^{14}$ M$_{\odot}$ > %.2f (0.2 < $z$ < 1)" % (extName, averageMassLimit_90Complete)) 

        # Another potentially useful sanity check plot - the fits themselves
        #plt.ion()
        #plt.close()
        #for key in completenessTab.keys():
            #if key != 'log10M':
                #plt.plot(completenessTab['log10M'], completenessTab[key], 'k.')
                #fitMask=np.equal(fitTab['z'], float(key))
                #plt.plot(completenessTab['log10M'], rayleighFlipped(completenessTab['log10M'], 
                                                                    #fitTab['loc'][fitMask], fitTab['scale'][fitMask]), label = key)
        #plt.legend()

    return fitTab

#------------------------------------------------------------------------------------------------------------
def makeMassLimitMap(SNRCut, z, extName, photFilterLabel, mockSurvey, scalingRelationDict, tckQFitDict, 
                     diagnosticsDir):
    """Makes a map of 90% mass completeness (for now, this fraction is fixed).
    
    """
    
    # Get the stuff we need...
    RMSImg=pyfits.open(diagnosticsDir+os.path.sep+"RMSMap_Arnaud_M2e14_z0p4#%s.fits" % (extName))
    RMSMap=RMSImg[0].data
    areaImg=pyfits.open(diagnosticsDir+os.path.sep+"areaMask#%s.fits" % (extName))
    areaMap=areaImg[0].data
    wcs=astWCS.WCS(areaImg[0].header, mode = 'pyfits')
    RMSTab=getRMSTab(extName, photFilterLabel, diagnosticsDir)

    # Fill in blocks in map for each RMS value, and store giant fit table for this z also
    massLimMap=np.zeros(RMSMap.shape)
    mapFitTab=None
    count=0
    t0=time.time()
    for y0Noise in RMSTab['y0RMS']:
        count=count+1
        print("... %d/%d ..." % (count, len(RMSTab)))
        fitTab=calcCompleteness(y0Noise, SNRCut, extName, mockSurvey, parDict['massOptions'], tckQFitDict, diagnosticsDir,
                                zRange = [z], fitTabFileName = None)
        fitTab.rename_column('z', 'y0RMS')
        fitTab['y0RMS'][0]=y0Noise
        massLimMap[np.where(RMSMap == y0Noise)]=fitTab['log10MLimit_90%'][0]
        if mapFitTab == None:
            mapFitTab=fitTab
        else:
            mapFitTab.add_row(fitTab[0])
    t1=time.time()
    
    outFileName=diagnosticsDir+os.path.sep+"massLimitMap_z%s#%s.fits" % (str(z).replace(".", "p"), extName)
    astImages.saveFITS(outFileName, np.power(10, massLimMap)/1e14, wcs)

    outFileName=diagnosticsDir+os.path.sep+"selFn_mapFitTab_z%s#%s.fits" % (str(z).replace(".", "p"), extName)
    if os.path.exists(outFileName) == True:
        os.remove(outFileName)
    mapFitTab.write(outFileName)
    
#------------------------------------------------------------------------------------------------------------
def makeMassLimitVRedshiftPlot(massLimit_90Complete, zRange, outFileName, title = None):
    """Write a plot of 90%-completeness mass limit versus z, adding a spline interpolation.
    
    """
    
    plotSettings.update_rcParams()
    plt.figure(figsize=(9,6.5))
    if title == None:
        ax=plt.axes([0.10, 0.11, 0.87, 0.86])
    else:
        ax=plt.axes([0.10, 0.11, 0.87, 0.80])
    tck=interpolate.splrep(zRange, massLimit_90Complete)
    plotRange=np.linspace(0, 2, 100)
    plt.plot(plotRange, interpolate.splev(plotRange, tck), 'k-')
    plt.plot(zRange, massLimit_90Complete, 'D', ms = 8)
    plt.xlabel("$z$")
    plt.ylim(0.5, 8)
    plt.xticks(np.arange(0, 2.2, 0.2))
    plt.xlim(0, 2)
    labelStr="$M_{\\rm 500c}$ (10$^{14}$ M$_{\odot}$) [90% complete]"
    plt.ylabel(labelStr)
    if title != None:
        plt.title(title)
    plt.savefig(outFileName)
    plt.close()   
    
#------------------------------------------------------------------------------------------------------------
# Main
if len(sys.argv) < 2:
    print "Run: % nemoSelFn < .par file(s)>"
else:
    
    parDictFileNames=sys.argv[1:]
    
    for parDictFileName in parDictFileNames:
    
        # This first part is all the same as the main nemo script
        print ">>> Running .par file: %s" % (parDictFileName)
        parDict=actDict.ACTDict()
        parDict.read_from_file(parDictFileName)

        MPIEnabled=parDict['useMPI']
        if MPIEnabled ==True:
            from mpi4py import MPI
            comm=MPI.COMM_WORLD
            size=comm.Get_size()
            rank=comm.Get_rank()
            if size == 1:
                raise Exception, "if you want to use MPI, run with e.g., mpirun --np 4 nemoSelFn ..."
        else:
            rank=0

        # Output dirs
        if 'outputDir' in parDict.keys():
            rootOutDir=parDict['outDir']
        else:
            if parDictFileName.find(".par") == -1:
                raise Exception, "File must have .par extension"
            rootOutDir=sys.argv[1].replace(".par", "")
        filteredMapsDir=rootOutDir+os.path.sep+"filteredMaps"
        filtersDir=rootOutDir+os.path.sep+"filters"
        diagnosticsDir=rootOutDir+os.path.sep+"diagnostics"
        dirList=[rootOutDir, filteredMapsDir, filtersDir]
        if rank == 0:
            for d in dirList:
                if os.path.exists(d) == False:
                    os.makedirs(d)
                    
        # Optional override of default GNFW parameters (used by Arnaud model), if used in filters given
        if 'GNFWParams' not in parDict.keys():
            parDict['GNFWParams']='default'
        for filtDict in parDict['mapFilters']:
            filtDict['params']['GNFWParams']=parDict['GNFWParams']

        # tileDeck file handling - either make one, or handle loading of one
        # MPI: if the tileDeck doesn't exist, only one process makes it - the others wait until it is done
        if rank == 0:
            unfilteredMapsDictList, extNames=mapTools.makeTileDeck(parDict)
            madeTileDeck=True
        else:
            madeTileDeck=None
        if MPIEnabled == True:
            madeTileDeck=comm.bcast(madeTileDeck, root = 0)
            if rank != 0 and madeTileDeck == True:
                unfilteredMapsDictList, extNames=mapTools.makeTileDeck(parDict)
            
        # For when we want to test on only a subset of tiles
        if 'extNameList' in parDict.keys():
            newList=[]
            for name in extNames:
                if name in parDict['extNameList']:
                    newList.append(name)
            if newList == []:
                raise Exception, "extNameList given in .par file but no extensions in images match"
            extNames=newList
        
        # MPI: just divide up tiles pointed at by extNames among processes
        if MPIEnabled == True:
            numTilesPerNode=len(extNames)/size
            startIndex=numTilesPerNode*rank
            if rank == size-1:
                endIndex=len(extNames)
            else:
                endIndex=numTilesPerNode*(rank+1)
        else:
            startIndex=0
            endIndex=len(extNames)
        extNames=extNames[startIndex:endIndex]

        # Now we get into selection function stuff...
        # Q varies across tiles
        tckQFitDict=simsTools.fitQ(parDict, diagnosticsDir, filteredMapsDir)

        # Since a fiducial cosmology (OmegaM0 = 0.3, OmegaL0 = 0.7, H0 = 70 km/s/Mpc) was used in the object detection/filtering stage, we use the same one here      
        minMass=5e13
        areaDeg2=400.0  # Don't care what value this has, as we'll sim up an arbitrary number of clusters anyway
        zMin=0.0
        zMax=2.0
        H0=70.
        Om0=0.30
        Ob0=0.05
        sigma_8=0.8
        mockSurvey=MockSurvey.MockSurvey(minMass, areaDeg2, zMin, zMax, H0, Om0, Ob0, sigma_8, enableDrawSample = True)
        
        # We only care about the filter used for fixed_ columns
        photFilterLabel=parDict['photometryOptions']['photFilter']
        for filterDict in parDict['mapFilters']:
            if filterDict['label'] == photFilterLabel:
                break

        # We'll only calculate completeness for this given selection
        SNRCut=parDict['selFnOptions']['fixed_SNR_cut']

        # Run the selection function calculation on each tile in turn
        selFnDictList=[]
        for extName in extNames:
            tileAreaDeg2=getTileTotalAreaDeg2(extName, diagnosticsDir)
            y0Noise=calcTileWeightedAverageNoise(extName, photFilterLabel, diagnosticsDir)
            fitTab=calcCompleteness(y0Noise, SNRCut, extName, mockSurvey, parDict['massOptions'], tckQFitDict, diagnosticsDir,
                                    fitTabFileName = diagnosticsDir+os.path.sep+"selFn_fitTab#%s.fits" % (extName))
            # We will eventually want to use interpolation of fitTab results to make 2d completeness array on mockSurvey grid, as used in HSC stuff
            selFnDict={'extName': extName,
                       'y0Noise': y0Noise,
                       'tileAreaDeg2': tileAreaDeg2,
                       'fitTab': fitTab}
            selFnDictList.append(selFnDict)

            # Optional mass-limit maps
            if 'massLimitMaps' in parDict['selFnOptions'].keys():
                for massLimitDict in parDict['selFnOptions']['massLimitMaps']:
                    makeMassLimitMap(SNRCut, massLimitDict['z'], extName, photFilterLabel, mockSurvey, 
                                     parDict['massOptions'], tckQFitDict, diagnosticsDir)
                    #print("what now?")
                    #IPython.embed()
                    #sys.exit()            
            
            
        # MPI: gather together selection function results, so we can compute survey-wide average
        if MPIEnabled == True:
            gathered_selFnDictLists=comm.gather(selFnDictList, root = 0)
            if rank != 0:
                assert gathered_selFnDictLists is None
                print "... MPI rank %d finished ..." % (rank)
                sys.exit()
            else:
                print "... gathering selection function results ..."
                all_selFnDictList=[]
                for dictList in gathered_selFnDictLists:
                    all_selFnDictList=selFnDictList+dictList
        else:
            all_selFnDictList=selFnDictList
                
        # Survey-averaged 90% mass completeness limit
        tileAreas=[]
        completeness=[]
        for selFnDict in all_selFnDictList:
            tileAreas.append(selFnDict['tileAreaDeg2'])
            completeness.append(np.array(selFnDict['fitTab']['log10MLimit_90%']))
        tileAreas=np.array(tileAreas)
        fracArea=tileAreas/np.sum(tileAreas)
        completeness=np.array(completeness)
        zRange=np.array(selFnDict['fitTab']['z'])
        #massLimit_90Complete=np.average(np.power(10, completeness)/1e14, axis = 0, weights = fracArea)
        massLimit_90Complete=np.power(10, np.average(completeness, axis = 0, weights = fracArea))/1e14
        makeMassLimitVRedshiftPlot(massLimit_90Complete, zRange, diagnosticsDir+os.path.sep+"completeness90Percent_surveyAverage.pdf")
        
        print(">>> Survey-averaged results:")
        averageMassLimit_90Complete=massLimit_90Complete[np.logical_and(np.greater(zRange, 0.2), np.less(zRange, 1.0))].mean()
        print("... total survey area (after masking) = %.3f sq deg ..." % (np.sum(tileAreas)))
        print("... survey-averaged 90%% mass completeness limit (0.2 < z < 1.0) = %.3f x 10^14 MSun" % (averageMassLimit_90Complete))

            
            
            
